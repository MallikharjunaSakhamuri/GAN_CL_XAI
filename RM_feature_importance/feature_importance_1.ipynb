{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GacT624H6abN"
      },
      "source": [
        "# Explaining Feature Importance by example of a Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5DtZ5D-6abP"
      },
      "source": [
        "In many (business) cases it is equally important to not only have an accurate, but also an interpretable model. Oftentimes, apart from wanting to know what our model's house price prediction is, we also wonder why it is this high/low and which features are most important in determining the forecast Another example might be predicting customer churn - it is very nice to have a model that is successfully predicting which customers are prone to churn, but identifying which variables are important can help us in early detection and maybe even improving the product/service!\n",
        "\n",
        "Knowing feature importance indicated by machine learning models can benefit you in multiple ways, here are some examples:\n",
        "* by getting a better understanding of the model's logic you can not only verify it being correct, but also work on improving the model by focusing only on the important variables\n",
        "* the above can be used for variable selection - you can remove x variables that are not that significant and have similar or better performance in much shorter training time\n",
        "* in some business cases it makes sense to sacrifice some accuracy for the sake of interpretability. For example, when a bank rejects a loan application, it must also have a reasoning behind the decision, which can also be presented to the customer\n",
        "\n",
        "That is why in this article I would like to explore different approaches to interpreting feature importance by example of a Random Forest model. Most of them are also applicable to different models, starting from linear regression and ending with black-boxes such as XGBoost.\n",
        "\n",
        "One thing to note is that the more accurate our model is, the more we can trust feature importance measures and other interpretations. I assume that the model we build is reasonably accurate (as each data scientist will strive to have such a model) and in this article I focus on importance measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8cf4dVu6abR"
      },
      "source": [
        "## Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:08.271143Z",
          "start_time": "2019-02-11T20:44:07.434388Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "r2OgEEon6abR",
        "outputId": "f40320c1-0862-4605-b84f-14266ff0b331"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d52d4cfa854>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m from pandas.core.groupby import (\n\u001b[1;32m     70\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0msanitize_masked_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0;31m from pandas.core.generic import (\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmake_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mndarray_to_mgr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m )\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescribe_ndframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m from pandas.core.missing import (\n\u001b[1;32m    186\u001b[0m     \u001b[0mclean_fill_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformat_percentiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m from pandas.io.common import (\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mstringify_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# visualisations\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set(rc = {'figure.figsize':(15, 10)})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hs119kE6abS"
      },
      "source": [
        "I define a few helper functions to make analysis more convenient and presentable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:08.282032Z",
          "start_time": "2019-02-11T20:44:08.273342Z"
        },
        "id": "C0TYY3uE6abT"
      },
      "outputs": [],
      "source": [
        "# udfs ----\n",
        "\n",
        "# function for creating a feature importance dataframe\n",
        "def imp_df(column_names, importances):\n",
        "    df = pd.DataFrame({'feature': column_names,\n",
        "                       'feature_importance': importances}) \\\n",
        "           .sort_values('feature_importance', ascending = False) \\\n",
        "           .reset_index(drop = True)\n",
        "    return df\n",
        "\n",
        "# plotting a feature importance dataframe (horizontal barchart)\n",
        "def var_imp_plot(imp_df, title):\n",
        "    imp_df.columns = ['feature', 'feature_importance']\n",
        "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n",
        "       .set_title(title, fontsize = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or8_yxFA6abT"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFoa2EZK6abT"
      },
      "source": [
        "For this example I will use the Boston house prices dataset (so a regression problem). But the approaches described in this article work just as well with classification problems, the only difference is the metric used for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:08.294285Z",
          "start_time": "2019-02-11T20:44:08.284520Z"
        },
        "id": "T-dzJuF-6abU"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "print(boston.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-s-KODg6abV"
      },
      "source": [
        "The only non-standard thing in preparing the data is the addition of a random column to the dataset. Logically, it has no predictive power over the dependent variable (Median value of owner-occupied homes in $1000's), so it should not be an important feature in the model. Let's see how it will turn out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:08.306098Z",
          "start_time": "2019-02-11T20:44:08.297298Z"
        },
        "id": "sn7yDQhK6abV"
      },
      "outputs": [],
      "source": [
        "y = boston.target\n",
        "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "np.random.seed(seed = 42)\n",
        "X['random'] = np.random.random(size = len(X))\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rctB73cp6abV"
      },
      "source": [
        "Below I inspect the relationship between the random feature and the target variable. As it can be observed, there is no pattern on the scatterplot and the correlation is almost 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:08.674222Z",
          "start_time": "2019-02-11T20:44:08.308373Z"
        },
        "id": "speZuim36abV"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x = 'random', y = 'target', data = X.assign(target = y)).set_title('Random feature vs. target variable', fontsize = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T21:45:01.003792Z",
          "start_time": "2019-02-11T21:45:00.326726Z"
        },
        "id": "-lzFPT7B6abV"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(X.assign(target = y).corr().round(2), cmap = 'Blues', annot = True).set_title('Correlation matrix', fontsize = 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Ne_vWh6abW"
      },
      "source": [
        "One thing to note here is that there is not much sense in interpreting the correlation for `CHAS`, as it is a binary variable and different methods should be used for it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3bpER0M6abW"
      },
      "source": [
        "## Benchmark model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9s6JfSl6abW"
      },
      "source": [
        "I train a plain Random Forest model to have a benchmark. I set a `random_state` to ensure results comparability. I also use bootstrap and set `oob_score = True` to later use the out-of-bag error.\n",
        "\n",
        "Briefly, each tree in the random forest is trained on a different dataset, sampled with replacement from the original data. This results in around ~2/3 of distinct observations in each training set. The out-of-bag error is calculated on all the observations, but for calculating each row's error the model only considers trees which have not seen this row during training. This is similar to evaluating the model on a validation set. You can read more [here](https://stackoverflow.com/questions/18541923/what-is-out-of-bag-error-in-random-forests)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T21:46:43.852767Z",
          "start_time": "2019-02-11T21:46:43.695489Z"
        },
        "id": "Eh87vTZE6abW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 100,\n",
        "                           n_jobs = -1,\n",
        "                           oob_score = True,\n",
        "                           bootstrap = True,\n",
        "                           random_state = 42)\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otNfin296abX"
      },
      "outputs": [],
      "source": [
        "print(f\"\"\"R^2 Training Score: {rf.score(X_train, y_train):.2f}\n",
        "OOB Score: {rf.oob_score_:.2f}\n",
        "R^2 Validation Score: {rf.score(X_valid, y_valid):.2f}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdCmM9_R6abX"
      },
      "source": [
        "Well, there is some overfitting in the model, as it performs much worse on OOB sample and worse on the validation set. But let's say it is good enough and move forward to feature importances (measured on the training set performance). Some of the approaches can also be used for validation/OOB sets, to gain further interpretability on the unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yps5yFQe6abX"
      },
      "source": [
        "## Overall feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FiACdKe6abX"
      },
      "source": [
        "By overall feature importances I mean the ones derived at model level, i.e., saying that in a given model these features are most important in explaining the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTnxiuwq6abX"
      },
      "source": [
        "### Default Scikit-learn's feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5XRtUX6abX"
      },
      "source": [
        "Let's start with decision trees to build some intuition. In decision trees, every node is a condition how to split values in a single feature, so that similar values of dependent variable end up in the same set after the split. The condition is based on impurity, which in case of classification problems is Gini impurity / information gain (entropy), while for regression trees its variance. So when training a tree we can compute how much each feature contributes to decreasing the weighted impurity. `feature_importances_` in Scikit-Learn is based on that logic, but in case of Random Forest we are talking about averaging the decrease in impurity over trees.\n",
        "\n",
        "Pros:\n",
        "* fast calculation\n",
        "* easy to retrieve - one command\n",
        "\n",
        "Cons:\n",
        "* biased approach, as it has a tendency to inflate the importance of continuous features or high-cardinality categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:09.955398Z",
          "start_time": "2019-02-11T20:44:09.837723Z"
        },
        "id": "RBPrB6H26abX"
      },
      "outputs": [],
      "source": [
        "base_imp = imp_df(X_train.columns, rf.feature_importances_)\n",
        "base_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:10.183260Z",
          "start_time": "2019-02-11T20:44:09.957871Z"
        },
        "id": "okHbfCtY6abY"
      },
      "outputs": [],
      "source": [
        "var_imp_plot(base_imp, 'Default feature importance (scikit-learn)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUkze_P6abY"
      },
      "source": [
        "It seems that the top 3 most important features are:\n",
        "* average number of rooms   \n",
        "* % lower status of the population\n",
        "* weighted distances to five Boston employment centres\n",
        "\n",
        "What seems surprising though is that a column of random values turned out to be more important than:\n",
        "* proportion of non-retail business acres per town\n",
        "* index of accessibility to radial highways\n",
        "* proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "* Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "\n",
        "Intuitively this feature should have zero importance on the target variable. Let's see how it is evaluated by different approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdVGJuiz6abY"
      },
      "source": [
        "### Permutation feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuz9VBQy6abY"
      },
      "source": [
        "This approach directly measures feature importance by observing how random re-shuffling (thus preserving the distribution of the variable) of each predictor influences model performance.\n",
        "\n",
        "The approach can be described in the following steps:\n",
        "1. Train the baseline model and record the score (accuracy/R^2/any metric of importance) by passing validation set (or OOB set in case of Random Forest). This can also be done on the training set, at the cost of sacrificing information about generalisation.\n",
        "2. Re-shuffle values from one feature in the selected dataset, pass the dataset to the model again to obtain predictions and calculate the metric for this modified dataset. The feature importance is the difference between the benchmark score and the one from the modified (permuted) dataset.\n",
        "3. Repeat 2. for all feature in the dataset.\n",
        "\n",
        "Pros:\n",
        "* applicable to any model\n",
        "* reasonably efficient\n",
        "* reliable technique\n",
        "* no need to retrain the model at each modification of the dataset\n",
        "\n",
        "Cons:\n",
        "* more computationally expensive than default `feature_importances`\n",
        "* permutation importance overestimates the importance of correlated predictors - Strobl *et al* (2008)\n",
        "\n",
        "As for the second problem with this method, I have already plotted the correlation matrix above. However, I will use a function from one of the libraries I use to visualise Spearman's correlations. The difference between standard Pearson's correlation is that this one first transforms variables into ranks and only then runs Pearson's correlation on the ranks.\n",
        "\n",
        "Spearman's correlation:\n",
        "* is nonparametric\n",
        "* does not assume linear relationship between variables\n",
        "* it looks for monotonic relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:11.261158Z",
          "start_time": "2019-02-11T20:44:10.185499Z"
        },
        "id": "BqWfCKge6abY"
      },
      "outputs": [],
      "source": [
        "from rfpimp import plot_corr_heatmap\n",
        "viz = plot_corr_heatmap(X_train, figsize=(15,10))\n",
        "viz.view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:40:53.763199Z",
          "start_time": "2019-02-11T20:40:53.757965Z"
        },
        "id": "KUxL_y6i6abZ"
      },
      "source": [
        "I found two libraries with this functionality, not that it is difficult to code it. Let's go over both of them as they have some unique features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdNHvzIH6abZ"
      },
      "source": [
        "#### rfpimp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7NQB9FR6abZ"
      },
      "source": [
        "One thing to note about this library is that we have to provide a metric as a function of the form `metric(model, X, y)`. This way we can use more advanced approaches such as using the OOB score of Random Forest. This library already contains functions for that (`oob_regression_r2_score`). But to keep the approach uniform, I will calculate the metrics on the training set (losing information about generalisation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:12.867057Z",
          "start_time": "2019-02-11T20:44:11.263343Z"
        },
        "id": "1ZCtdexQ6abZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from rfpimp import permutation_importances\n",
        "\n",
        "def r2(rf, X_train, y_train):\n",
        "    return r2_score(y_train, rf.predict(X_train))\n",
        "\n",
        "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)\n",
        "perm_imp_rfpimp.reset_index(drop = False, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:44:13.134809Z",
          "start_time": "2019-02-11T20:44:12.869983Z"
        },
        "id": "432ZDkbo6aba"
      },
      "outputs": [],
      "source": [
        "var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:43:45.006124Z",
          "start_time": "2019-02-11T20:43:45.001048Z"
        },
        "id": "sIZiD-FK6aba"
      },
      "source": [
        "The plot confirms what we have seen above, that 4 variables are less important than a random variable! Surprising... The top 4 stayed the same though. One more nice feature about `rfpimp` is that it contains functionalities for dealing with the issue of collinear features (that was the idea behind showing the Spearman's correlation matrix). For brevity I will not show this case here, but you can read more in this great [article](https://explained.ai/rf-importance/index.html#5) by the authors of the library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVsEZs6r6aba"
      },
      "source": [
        "#### eli5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtgCv3AA6aba"
      },
      "source": [
        "There are a few differences from the basic approach of `rfpimp` and the one employed in `eli5`.\n",
        "Some of them are:\n",
        "* there are parameters `cv` and `refit` connected to using cross-validation. In this example I set them to `None`, as I do not use it but it might come in handy in some cases.\n",
        "* there is a `metric` parameter, which as in `rfpimp` accepts a function in the form of `metric(model, X, y)`. If this parameter is not specified, the function will use the default `score` method of the estimator.\n",
        "* `n_iter` - number of random shuffle iterations, the end score is the average    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:27.495422Z",
          "start_time": "2019-02-11T20:44:13.137067Z"
        },
        "id": "AH8M23Fr6abb"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X_train, y_train)\n",
        "perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)\n",
        "var_imp_plot(perm_imp_eli5, 'Permutation feature importance (eli5)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANapyiXF6abf"
      },
      "source": [
        "The results are very similar to the previous ones, even as these came from multiple reshuffles per column.\n",
        "\n",
        "The default importance DataFrame is not the most readable, as it does not contain variable names. This can be of course quite easily fixed. The nice thing is the standard error from all iterations of the reshuffling on each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:27.528208Z",
          "start_time": "2019-02-11T20:45:27.498329Z"
        },
        "id": "1fHMTusp6abf"
      },
      "outputs": [],
      "source": [
        "eli5.show_weights(perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zAqefHd6abg"
      },
      "source": [
        "One extra nice thing about `eli5` is that it is really easy to use the results of permutation approach to carry out feature selection by using Scikit-learn's `SelectFromModel` or `RFE`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNud583N6abg"
      },
      "source": [
        "### Drop Column feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjaJUicT6abg"
      },
      "source": [
        "This approach is quite an intuitive one, as we investigate the importance of a feature by comparing a model with all features versus a model with this feature dropped for training.\n",
        "\n",
        "I created a function (based on `rfpimp`'s implementation) for this approach below, which shows the underlying logic.\n",
        "\n",
        "Pros:\n",
        "* most accurate feature importance\n",
        "\n",
        "Cons:\n",
        "* potentially high computation cost due to retraining the model for each variant of the dataset (after dropping a single feature column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:27.548869Z",
          "start_time": "2019-02-11T20:45:27.530695Z"
        },
        "id": "DOq4_9256abg"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "def drop_col_feat_imp(model, X_train, y_train, random_state = 42):\n",
        "\n",
        "    # clone the model to have the exact same specification as the one initially trained\n",
        "    model_clone = clone(model)\n",
        "    # set random_state for comparability\n",
        "    model_clone.random_state = random_state\n",
        "    # training and scoring the benchmark model\n",
        "    model_clone.fit(X_train, y_train)\n",
        "    benchmark_score = model_clone.score(X_train, y_train)\n",
        "    # list for storing feature importances\n",
        "    importances = []\n",
        "\n",
        "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
        "    for col in X_train.columns:\n",
        "        model_clone = clone(model)\n",
        "        model_clone.random_state = random_state\n",
        "        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
        "        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
        "        importances.append(benchmark_score - drop_col_score)\n",
        "\n",
        "    importances_df = imp_df(X_train.columns, importances)\n",
        "    return importances_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.559043Z",
          "start_time": "2019-02-11T20:45:27.551122Z"
        },
        "id": "MtnTUoOs6abg"
      },
      "outputs": [],
      "source": [
        "drop_imp = drop_col_feat_imp(rf, X_train, y_train)\n",
        "var_imp_plot(drop_imp, 'Drop Column feature importance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmPhFtBE6abh"
      },
      "source": [
        "Here it gets interesting. First of all, negative importance in this case means that removing a given feature from the model actually improves the performance. So this is nice to see in case of `random`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCMSRseO6abh"
      },
      "source": [
        "## Observation level feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M0zpQjJ6abh"
      },
      "source": [
        "By observation level feature importances I mean ones that had most impact on explaining a particular observation fed to the model. For example, in case of credit scoring, we would be able to say that these features had most impact on determining client's credit score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7HV0X_56abh"
      },
      "source": [
        "### Treeinterpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW-eefIG6abh"
      },
      "source": [
        "The main idea of `treeinterpreter` is that it uses the underlying trees in Random Forest to explain how each feature contributes the end value. We can observe how the value of the prediction (defined as the sum of each feature contributions + average given by the initial node that is based on the entire training set) changes along the prediction path within the decision tree (after every split), together with the information which feature caused the split (so also the change in prediction).\n",
        "\n",
        "The formula for the prediction function ($f(x)$) can be written down as:\n",
        "$$ f(x) = c_{full} +\\sum_{k=1}^{K}contribution(x, k)$$\n",
        "\n",
        "where $c_{full}$ is the average of the entire dataset (initial node), $K$ is the total number of features.\n",
        "\n",
        "This may sound complicated, but take a look at an example from the author of the library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.566279Z",
          "start_time": "2019-02-11T20:45:31.561115Z"
        },
        "id": "6_se_RWp6abh"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<img src=\"img/dec_tree.png\",width=40,height=40>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psi4Rko6abh"
      },
      "source": [
        "As Random Forest's prediction is the average of the trees, the formula for average prediction is the following:\n",
        "\n",
        "$$F(x) = \\frac{1}{J} \\sum_{j=1}^{J} c_{j_{full}} + \\sum_{k=1}^{K}(\\frac{1}{J}\\sum_{j=1}^{J}contribution_{j}(x,k))$$\n",
        "\n",
        "where $J$ is the number of trees in the forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-09T22:40:22.532420Z",
          "start_time": "2019-02-09T22:40:22.523811Z"
        },
        "id": "cquo7qpJ6abi"
      },
      "source": [
        "I start by identifying rows with lowest and highest absolute prediction error and will try to see what caused the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.685735Z",
          "start_time": "2019-02-11T20:45:31.568456Z"
        },
        "id": "Ejv9KbAw6abi"
      },
      "outputs": [],
      "source": [
        "pred_diff = pd.DataFrame({'difference': abs(y_train - rf.predict(X_train))})\n",
        "\n",
        "print('Index with smallest error:', pred_diff.sort_values('difference').head(1).index.values[0])\n",
        "print('Index with largest error:', pred_diff.sort_values('difference', ascending = False).head(1).index.values[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxsjh_Aj6abi"
      },
      "source": [
        "Using `treeintrerpreter` I obtain 3 objects: predictions, bias (average value of the dataset) and contributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.761437Z",
          "start_time": "2019-02-11T20:45:31.688279Z"
        },
        "id": "IWshiDYh6abj"
      },
      "outputs": [],
      "source": [
        "from treeinterpreter import treeinterpreter as ti, utils\n",
        "\n",
        "selected_rows = [5, 135]\n",
        "selected_df = X_train.iloc[selected_rows,:].values\n",
        "prediction, bias, contributions = ti.predict(rf, selected_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNjMYMof6abj"
      },
      "source": [
        "For the observation with smallest error, the main contributor was `LSTAT` and `RM` (which in previous cases turned out to be most important variables). In the highest error case, the highest contribution came from `DIS` variable, overcoming the same two variables that played the most important role in the first case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.808493Z",
          "start_time": "2019-02-11T20:45:31.764267Z"
        },
        "id": "g13ZVZ6z6abk"
      },
      "outputs": [],
      "source": [
        "for i in range(len(selected_rows)):\n",
        "    print(\"Row\", selected_rows[i])\n",
        "    print(\"Prediction:\", prediction[i][0], 'Actual Value:', y_train[selected_rows[i]])\n",
        "    print(\"Bias (trainset mean)\", bias[i])\n",
        "    print(\"Feature contributions:\")\n",
        "    for c, feature in sorted(zip(contributions[i],\n",
        "                                 X_train.columns),\n",
        "                             key=lambda x: -abs(x[0])):\n",
        "        print(feature, round(c, 2))\n",
        "    print(\"-\"*20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAw2d1W16abk"
      },
      "source": [
        "To dive even deeper, we might also be interested in joined contribution of many variables (as explained in the case of XOR [here](http://blog.datadive.net/random-forest-interpretation-conditional-feature-contributions/)). I will go right to the example, more information can be found under the link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:31.997210Z",
          "start_time": "2019-02-11T20:45:31.811962Z"
        },
        "id": "RO6QEsSX6abk"
      },
      "outputs": [],
      "source": [
        "prediction1, bias1, contributions1 = ti.predict(rf, np.array([selected_df[0]]), joint_contribution=True)\n",
        "prediction2, bias2, contributions2 = ti.predict(rf, np.array([selected_df[1]]), joint_contribution=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:32.004873Z",
          "start_time": "2019-02-11T20:45:31.999629Z"
        },
        "id": "zPiYfjma6abk"
      },
      "outputs": [],
      "source": [
        "aggregated_contributions1 = utils.aggregated_contribution(contributions1)\n",
        "aggregated_contributions2 = utils.aggregated_contribution(contributions2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:32.032176Z",
          "start_time": "2019-02-11T20:45:32.007758Z"
        },
        "id": "ozHmR-Dt6abl"
      },
      "outputs": [],
      "source": [
        "res = []\n",
        "for k in set(aggregated_contributions1.keys()).union(\n",
        "              set(aggregated_contributions2.keys())):\n",
        "    res.append(([X_train.columns[index] for index in k] ,\n",
        "               aggregated_contributions1.get(k, 0) - aggregated_contributions2.get(k, 0)))\n",
        "\n",
        "for lst, v in (sorted(res, key=lambda x:-abs(x[1])))[:10]:\n",
        "    print (lst, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9iLDG16abl"
      },
      "source": [
        "The most of the difference between the best and worst predicted cases comes from the number of rooms (`RM`) feature, in conjunction with weighted distances to five Boston employment centres (`DIS`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kezS3jJs6abl"
      },
      "source": [
        "### LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-09T23:05:24.485499Z",
          "start_time": "2019-02-09T23:05:24.470199Z"
        },
        "id": "iGo0KvTw6abl"
      },
      "source": [
        "LIME (Local Interpretable Model-agnostic Explanations) is a technique explaining the predictions of any classifier/regressor in an interpretable and faithful manner. To do so, an explanation is obtained by locally approximating the selected model with an interpretable one (such as linear models with regularisation or decision trees). The interpretable models are trained on small perturbations (adding noise) of the original observation (row in case of tabular data), thus they only provide good local approximation.\n",
        "\n",
        "Some drawbacks to be aware of:\n",
        "* only linear models are used to approximate local behaviour\n",
        "* type of perturbations that need to be performed on the data to obtain correct explanations are often use-case specific\n",
        "* simple (default) perturbations are often not enough. In an ideal case, the modifications would be driven by the variation that is observed in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:32.053189Z",
          "start_time": "2019-02-11T20:45:32.034881Z"
        },
        "id": "3yKng8cj6abm"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
        "                                                   mode = 'regression',\n",
        "                                                   feature_names = X_train.columns,\n",
        "                                                   categorical_features=[3],\n",
        "                                                   categorical_names=['CHAS'],\n",
        "                                                   discretize_continuous = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocPHnZZZ6abm"
      },
      "source": [
        "Below you can see the output of LIME interpretation.\n",
        "\n",
        "There are 3 parts of the output:\n",
        "1. Predicted value\n",
        "2. Feature importance - in case of regression it shows whether it has a negative or positive impact on the prediction, sorted by absolute impact descending.\n",
        "3. Actual values of these features for the explained rows.\n",
        "\n",
        "Note that LIME has discretized the features in the explanation. This is because of setting `discretize_continuous=True` in the constructor above. The reason for discretization is that it gives continuous features more intuitive explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-11T20:45:33.001836Z",
          "start_time": "2019-02-11T20:45:32.055530Z"
        },
        "id": "130dOVXu6abm"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "exp = explainer.explain_instance(X_train.values[5], rf.predict, num_features=5)\n",
        "exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed\n",
        "\n",
        "np.random.seed(42)\n",
        "exp = explainer.explain_instance(X_train.values[135], rf.predict, num_features=5)\n",
        "exp.show_in_notebook(show_all=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-09T23:23:44.171251Z",
          "start_time": "2019-02-09T23:23:43.778907Z"
        },
        "id": "PYHyY2dO6abn"
      },
      "source": [
        "LIME interpretation agrees that for these two observations the most important features are `RM` and `LSTAT`, which was also indicated by previous approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwh3KZlX6abn"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jMRM8FA6abn"
      },
      "source": [
        "In this article I showed a few approaches to deriving feature importances from machine learning models (not limited to Random Forest). I believe that understanding results is often as much important as having good results, thus every data scientist should do his/her best to understand which variables are the most important for the model and why. Not only can this help getting a better business understanding, but also can lead to further improvements of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBqLkn_s6abo"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrotI6U86abo"
      },
      "source": [
        "* [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "* [Conditional variable importance for random forests](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307)\n",
        "* [Interpreting random forests](http://blog.datadive.net/interpreting-random-forests/)\n",
        "* [Random forest interpretation – conditional feature contributions](http://blog.datadive.net/random-forest-interpretation-conditional-feature-contributions/)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ffd07b64928e1e927f34974c45036581f12be0ff4d37550e26c4888777a51c9b"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "336px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}