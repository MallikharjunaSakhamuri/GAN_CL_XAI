{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n",
      "Loaded 41 molecules\n",
      "Embedding dimension: 128\n",
      "\n",
      "==================== Analyzing Molecule 0 ====================\n",
      "\n",
      "Analyzing molecule 0 with SHAP...\n",
      "\n",
      "Top 5 Important Dimensions (SHAP):\n",
      "Dimension 118: 0.0356\n",
      "Dimension 65: 0.0462\n",
      "Dimension 60: 0.0543\n",
      "Dimension 31: 0.0684\n",
      "Dimension 43: 0.0702\n",
      "\n",
      "Analyzing molecule 0 with LIME...\n",
      "\n",
      "Top 5 Important Features (LIME):\n",
      "dim_115 <= -0.02: 0.0286\n",
      "dim_91 <= -0.10: 0.0311\n",
      "dim_2 <= 0.01: 0.0353\n",
      "dim_114 > 0.05: 0.0411\n",
      "dim_100 <= -0.08: 0.0695\n",
      "\n",
      "==================== Analyzing Molecule 1 ====================\n",
      "\n",
      "Analyzing molecule 1 with SHAP...\n",
      "\n",
      "Top 5 Important Dimensions (SHAP):\n",
      "Dimension 18: 0.0324\n",
      "Dimension 92: 0.0351\n",
      "Dimension 86: 0.0356\n",
      "Dimension 111: 0.0374\n",
      "Dimension 74: 0.0419\n",
      "\n",
      "Analyzing molecule 1 with LIME...\n",
      "\n",
      "Top 5 Important Features (LIME):\n",
      "dim_41 > 0.01: 0.0228\n",
      "dim_35 <= -0.03: 0.0257\n",
      "dim_74 > 0.03: 0.0274\n",
      "dim_92 <= -0.05: 0.0284\n",
      "dim_115 <= -0.02: 0.0416\n",
      "\n",
      "==================== Analyzing Molecule 2 ====================\n",
      "\n",
      "Analyzing molecule 2 with SHAP...\n",
      "\n",
      "Top 5 Important Dimensions (SHAP):\n",
      "Dimension 66: 0.0202\n",
      "Dimension 24: 0.0219\n",
      "Dimension 126: 0.0222\n",
      "Dimension 54: 0.0726\n",
      "Dimension 16: 0.0902\n",
      "\n",
      "Analyzing molecule 2 with LIME...\n",
      "\n",
      "Top 5 Important Features (LIME):\n",
      "dim_35 <= -0.03: 0.0145\n",
      "dim_78 > 0.05: 0.0154\n",
      "dim_112 <= -0.06: 0.0182\n",
      "dim_114 <= -0.04: 0.0220\n",
      "dim_116 <= -0.12: 0.0327\n",
      "\n",
      "Analysis complete. Results saved in xai_analysis/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import pickle\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class GraphDiscriminator(nn.Module):\n",
    "    \"\"\"Reimplementation of original discriminator architecture\"\"\"\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int = 128, output_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature encoding\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "        \n",
    "        # Projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = torch.cat([data.x_cat.float(), data.x_phys], dim=-1)\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr.float()\n",
    "        batch = data.batch\n",
    "        \n",
    "        # Initial feature encoding\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Graph convolutions\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Projection\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EmbeddingAnalyzer:\n",
    "    \"\"\"Analyzer for learned molecular embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_path: str):\n",
    "        \"\"\"Initialize analyzer with saved embeddings\"\"\"\n",
    "        print(\"Loading embeddings...\")\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.embeddings = data['embeddings']  # Shape: (n_molecules, embedding_dim)\n",
    "            self.graphs = data['labels']          # Original graph data\n",
    "            \n",
    "        print(f\"Loaded {len(self.embeddings)} molecules\")\n",
    "        print(f\"Embedding dimension: {self.embeddings.shape[1]}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        os.makedirs('xai_analysis/shap', exist_ok=True)\n",
    "        os.makedirs('xai_analysis/lime', exist_ok=True)\n",
    "        \n",
    "    def analyze_shap(self, molecule_idx: int, n_background: int = 100) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze embedding dimensions using SHAP\n",
    "        Args:\n",
    "            molecule_idx: Index of molecule to analyze\n",
    "            n_background: Number of background samples for SHAP\n",
    "        \"\"\"\n",
    "        print(f\"\\nAnalyzing molecule {molecule_idx} with SHAP...\")\n",
    "        \n",
    "        # Get target embedding\n",
    "        target_embedding = self.embeddings[molecule_idx]\n",
    "        \n",
    "        # Create background dataset\n",
    "        background_indices = np.random.choice(\n",
    "            len(self.embeddings), \n",
    "            min(n_background, len(self.embeddings)), \n",
    "            replace=False\n",
    "        )\n",
    "        background_data = self.embeddings[background_indices]\n",
    "        \n",
    "        # Train a simple classifier to predict similarity\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        similarity_model = RandomForestRegressor(n_estimators=100)\n",
    "        \n",
    "        # Calculate cosine similarities for training\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarities = cosine_similarity([target_embedding], background_data)[0]\n",
    "        \n",
    "        # Train model to predict similarity from embeddings\n",
    "        similarity_model.fit(background_data, similarities)\n",
    "        \n",
    "        # Initialize SHAP explainer\n",
    "        explainer = shap.TreeExplainer(similarity_model)\n",
    "        shap_values = explainer.shap_values(\n",
    "            target_embedding.reshape(1, -1),\n",
    "            check_additivity=False\n",
    "        )\n",
    "        \n",
    "        # Create visualizations\n",
    "        self._plot_shap_summary(\n",
    "            shap_values, \n",
    "            target_embedding,\n",
    "            f'xai_analysis/shap/molecule_{molecule_idx}'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'shap_values': shap_values,\n",
    "            'feature_importance': np.abs(shap_values).mean(axis=0),\n",
    "            'similarity_scores': similarities\n",
    "        }\n",
    "     \n",
    "    def _initialize_encoder(self, checkpoint: Dict) -> nn.Module:\n",
    "        \"\"\"Initialize encoder with saved weights\"\"\"\n",
    "        # Get model info\n",
    "        model_info = checkpoint.get('model_info', {})\n",
    "        node_dim = model_info.get('node_dim')\n",
    "        edge_dim = model_info.get('edge_dim')\n",
    "        \n",
    "        # Initialize model (using your GraphDiscriminator class)\n",
    "        encoder = GraphDiscriminator(\n",
    "            node_dim=node_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            hidden_dim=128,\n",
    "            output_dim=128\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        return encoder\n",
    "    \n",
    "    def analyze_lime(self, molecule_idx: int, n_samples: int = 1000) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze embedding using LIME\n",
    "        Args:\n",
    "            molecule_idx: Index of molecule to analyze\n",
    "            n_samples: Number of samples for LIME\n",
    "        \"\"\"\n",
    "        print(f\"\\nAnalyzing molecule {molecule_idx} with LIME...\")\n",
    "        \n",
    "        # Get target embedding\n",
    "        target_embedding = self.embeddings[molecule_idx]\n",
    "        \n",
    "        # Initialize LIME explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "            self.embeddings,\n",
    "            feature_names=[f'dim_{i}' for i in range(self.embeddings.shape[1])],\n",
    "            mode='regression'\n",
    "        )\n",
    "        \n",
    "        # Define prediction function for similarity\n",
    "        def similarity_predictor(x):\n",
    "            return cosine_similarity(x, target_embedding.reshape(1, -1))\n",
    "            \n",
    "        # Get LIME explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            target_embedding,\n",
    "            similarity_predictor,\n",
    "            num_features=20,\n",
    "            num_samples=n_samples\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        self._plot_lime_explanation(\n",
    "            explanation,\n",
    "            f'xai_analysis/lime/molecule_{molecule_idx}'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'explanation': explanation,\n",
    "            'feature_weights': dict(explanation.as_list())\n",
    "        }\n",
    "        \n",
    "    def _plot_shap_summary(self, shap_values: np.ndarray, \n",
    "                          target_embedding: np.ndarray, save_path: str):\n",
    "        \"\"\"Create SHAP summary plot\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Create summary plot\n",
    "        shap.summary_plot(\n",
    "            shap_values,\n",
    "            target_embedding.reshape(1, -1),\n",
    "            feature_names=[f'dim_{i}' for i in range(self.embeddings.shape[1])],\n",
    "            show=False\n",
    "        )\n",
    "        \n",
    "        plt.title('SHAP Values for Embedding Dimensions')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_path}_summary.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Create bar plot of feature importance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        importance = np.abs(shap_values).mean(axis=0)\n",
    "        \n",
    "        # Sort by importance\n",
    "        idx = np.argsort(importance)[-20:]  # Top 20 dimensions\n",
    "        plt.barh(\n",
    "            [f'dim_{i}' for i in idx],\n",
    "            importance[idx]\n",
    "        )\n",
    "        plt.title('Top 20 Important Embedding Dimensions')\n",
    "        plt.xlabel('Mean |SHAP Value|')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_path}_importance.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def _plot_lime_explanation(self, explanation, save_path: str):\n",
    "        \"\"\"Create LIME explanation plot\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        explanation.as_pyplot_figure()\n",
    "        plt.title('LIME Feature Weights')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_path}_explanation.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def analyze_molecule(self, molecule_idx: int) -> Dict:\n",
    "        \"\"\"Run complete analysis for a molecule\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # SHAP analysis\n",
    "        results['shap'] = self.analyze_shap(molecule_idx)\n",
    "        \n",
    "        # Print top SHAP features\n",
    "        importance = results['shap']['feature_importance']\n",
    "        top_dims = np.argsort(importance)[-5:]\n",
    "        print(\"\\nTop 5 Important Dimensions (SHAP):\")\n",
    "        for dim in top_dims:\n",
    "            print(f\"Dimension {dim}: {importance[dim]:.4f}\")\n",
    "            \n",
    "        # LIME analysis\n",
    "        results['lime'] = self.analyze_lime(molecule_idx)\n",
    "        \n",
    "        # Print top LIME features\n",
    "        weights = results['lime']['feature_weights']\n",
    "        print(\"\\nTop 5 Important Features (LIME):\")\n",
    "        for feature, weight in sorted(weights.items(), key=lambda x: abs(x[1]))[-5:]:\n",
    "            print(f\"{feature}: {weight:.4f}\")\n",
    "            \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run embedding analysis\"\"\"\n",
    "    try:\n",
    "        analyzer = EmbeddingAnalyzer(\n",
    "            embedding_path='./embeddings/final_embeddings_20250216_111005.pkl'\n",
    "        )\n",
    "        \n",
    "        # Analyze first few molecules\n",
    "        results = {}\n",
    "        for idx in range(3):\n",
    "            print(f\"\\n{'='*20} Analyzing Molecule {idx} {'='*20}\")\n",
    "            results[idx] = analyzer.analyze_molecule(idx)\n",
    "            \n",
    "        print(\"\\nAnalysis complete. Results saved in xai_analysis/\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
