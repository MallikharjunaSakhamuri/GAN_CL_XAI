{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data keys: dict_keys(['embeddings', 'labels'])\n",
      "\n",
      "Type of embeddings: <class 'numpy.ndarray'>\n",
      "Shape of embeddings: (41, 128)\n",
      "\n",
      "Type of labels: <class 'list'>\n",
      "First label: ('edge_index', tensor([[   0,    1,    1,  ..., 1418, 1394, 1419],\n",
      "        [   1,    0,    2,  ..., 1394, 1419, 1394]]))\n",
      "Type of first label: <class 'tuple'>\n",
      "\n",
      "Tuple contents:\n",
      "Item 0: <class 'str'>\n",
      "Value: edge_index\n",
      "Item 1: <class 'torch.Tensor'>\n",
      "Value: tensor([[   0,    1,    1,  ..., 1418, 1394, 1419],\n",
      "        [   1,    0,    2,  ..., 1394, 1419, 1394]])\n",
      "Loading encoder and embeddings...\n",
      "Loaded 41 molecules\n",
      "Embedding dimension: 128\n",
      "\n",
      "Parsing graph structure...\n",
      "\n",
      "Analyzing molecule 0...\n",
      "Running SHAP analysis...\n",
      "Error during analysis: need at least one array to concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Malli\\AppData\\Local\\Temp\\ipykernel_83792\\2094488411.py\", line 304, in main\n",
      "    shap_results = analyzer.analyze_molecular_features_shap(idx)\n",
      "  File \"C:\\Users\\Malli\\AppData\\Local\\Temp\\ipykernel_83792\\2094488411.py\", line 160, in analyze_molecular_features_shap\n",
      "    features = self._create_feature_matrix(molecule_data)\n",
      "  File \"C:\\Users\\Malli\\AppData\\Local\\Temp\\ipykernel_83792\\2094488411.py\", line 223, in _create_feature_matrix\n",
      "    return np.concatenate(features, axis=1)\n",
      "ValueError: need at least one array to concatenate\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import pickle\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
    "\n",
    "class GraphDiscriminator(nn.Module):\n",
    "    \"\"\"Reimplementation of original discriminator architecture\"\"\"\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int = 128, output_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature encoding\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "        \n",
    "        # Projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = torch.cat([data.x_cat.float(), data.x_phys], dim=-1)\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr.float()\n",
    "        batch = data.batch\n",
    "        \n",
    "        # Initial feature encoding\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Graph convolutions\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Projection\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MolecularXAIAnalyzer:\n",
    "    \"\"\"Analyzer for molecular embeddings using SHAP and LIME\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_path: str, embedding_path: str):\n",
    "        \"\"\"Initialize analyzer with saved model and embeddings\"\"\"\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load encoder and embeddings\n",
    "        self._load_model_and_data(encoder_path, embedding_path)\n",
    "        \n",
    "        # Create output directories\n",
    "        os.makedirs('xai_analysis/shap', exist_ok=True)\n",
    "        os.makedirs('xai_analysis/lime', exist_ok=True)\n",
    "        \n",
    "    def _load_model_and_data(self, encoder_path: str, embedding_path: str):\n",
    "        \"\"\"Load saved model and data\"\"\"\n",
    "        print(\"Loading encoder and embeddings...\")\n",
    "        \n",
    "        # Load encoder\n",
    "        checkpoint = torch.load(encoder_path, map_location=self.device)\n",
    "        self.encoder = self._initialize_encoder(checkpoint)\n",
    "        self.encoder.eval()\n",
    "        \n",
    "        # Load embeddings and graphs\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.embeddings = data['embeddings']  # Shape: (N, embedding_dim)\n",
    "            self.graph_data = data['labels']      # List of tuples with graph data\n",
    "            \n",
    "        print(f\"Loaded {len(self.embeddings)} molecules\")\n",
    "        print(f\"Embedding dimension: {self.embeddings.shape[1]}\")\n",
    "        \n",
    "        # Parse graph structure\n",
    "        self._parse_graph_structure()\n",
    "        \n",
    "    def _parse_graph_structure(self):\n",
    "        \"\"\"Parse graph structure from saved data\"\"\"\n",
    "        print(\"\\nParsing graph structure...\")\n",
    "        \n",
    "        # Each graph is a tuple of (key, value) pairs\n",
    "        self.graph_elements = {}\n",
    "        for item in self.graph_data[0]:  # Look at first graph\n",
    "            if isinstance(item, tuple):\n",
    "                key, value = item\n",
    "                self.graph_elements[key] = value\n",
    "                print(f\"Found element: {key}, type: {type(value)}\")\n",
    "                \n",
    "        self.feature_names = self._get_feature_names()\n",
    "        \n",
    "    def _get_feature_names(self) -> List[str]:\n",
    "        \"\"\"Get feature names from graph structure\"\"\"\n",
    "        feature_names = []\n",
    "        \n",
    "        # Add names for each feature based on graph structure\n",
    "        for key in self.graph_elements.keys():\n",
    "            if key in ['x_cat', 'x_phys']:\n",
    "                value = self.graph_elements[key]\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    n_features = value.shape[1]\n",
    "                    feature_names.extend([f\"{key}_{i}\" for i in range(n_features)])\n",
    "                    \n",
    "        return feature_names\n",
    "     \n",
    "    def _initialize_encoder(self, checkpoint: Dict) -> nn.Module:\n",
    "        \"\"\"Initialize encoder with saved weights\"\"\"\n",
    "        # Get model info\n",
    "        model_info = checkpoint.get('model_info', {})\n",
    "        node_dim = model_info.get('node_dim')\n",
    "        edge_dim = model_info.get('edge_dim')\n",
    "        \n",
    "        # Initialize model (using your GraphDiscriminator class)\n",
    "        encoder = GraphDiscriminator(\n",
    "            node_dim=node_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            hidden_dim=128,\n",
    "            output_dim=128\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        return encoder\n",
    "    \n",
    "    def analyze_molecular_features_shap(self, molecule_idx: int) -> Dict:\n",
    "        \"\"\"Analyze molecular features using SHAP\"\"\"\n",
    "        # Get molecule data\n",
    "        molecule_data = self.graph_data[molecule_idx]\n",
    "        molecule_embedding = self.embeddings[molecule_idx]\n",
    "        \n",
    "        # Create feature matrix\n",
    "        features = self._create_feature_matrix(molecule_data)\n",
    "        \n",
    "        # Initialize SHAP explainer\n",
    "        def model_fn(x):\n",
    "            return self.encoder(self._features_to_data(x))\n",
    "            \n",
    "        explainer = shap.KernelExplainer(model_fn, features)\n",
    "        shap_values = explainer.shap_values(features)\n",
    "        \n",
    "        # Create visualizations\n",
    "        self._visualize_shap_results(shap_values, molecule_idx)\n",
    "        \n",
    "        return {\n",
    "            'shap_values': shap_values,\n",
    "            'feature_importance': np.abs(shap_values).mean(axis=0),\n",
    "            'feature_names': self.feature_names\n",
    "        }\n",
    "        \n",
    "    def analyze_embedding_lime(self, molecule_idx: int) -> Dict:\n",
    "        \"\"\"Analyze embeddings using LIME\"\"\"\n",
    "        # Get molecule data\n",
    "        molecule_data = self.graph_data[molecule_idx]\n",
    "        molecule_embedding = self.embeddings[molecule_idx]\n",
    "        \n",
    "        # Create feature matrix\n",
    "        features = self._create_feature_matrix(molecule_data)\n",
    "        \n",
    "        # Initialize LIME explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "            features,\n",
    "            feature_names=self.feature_names,\n",
    "            mode='regression'\n",
    "        )\n",
    "        \n",
    "        def predict_fn(x):\n",
    "            return self.encoder(self._features_to_data(x)).detach().numpy()\n",
    "            \n",
    "        # Get explanation\n",
    "        exp = explainer.explain_instance(\n",
    "            features[0],\n",
    "            predict_fn,\n",
    "            num_features=len(self.feature_names)\n",
    "        )\n",
    "        \n",
    "        # Visualize results\n",
    "        self._visualize_lime_results(exp, molecule_idx)\n",
    "        \n",
    "        return {\n",
    "            'lime_explanation': exp,\n",
    "            'feature_weights': dict(exp.as_list())\n",
    "        }\n",
    "        \n",
    "    def _create_feature_matrix(self, molecule_data) -> np.ndarray:\n",
    "        \"\"\"Create feature matrix from molecule data\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Combine features from different elements\n",
    "        for key in ['x_cat', 'x_phys']:\n",
    "            if key in self.graph_elements:\n",
    "                value = self.graph_elements[key]\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    features.append(value.numpy())\n",
    "                    \n",
    "        return np.concatenate(features, axis=1)\n",
    "        \n",
    "    def _features_to_data(self, features: np.ndarray) -> Data:\n",
    "        \"\"\"Convert feature matrix back to graph data\"\"\"\n",
    "        # Split features back into original components\n",
    "        start = 0\n",
    "        data_dict = {}\n",
    "        \n",
    "        for key in ['x_cat', 'x_phys']:\n",
    "            if key in self.graph_elements:\n",
    "                value = self.graph_elements[key]\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    n_features = value.shape[1]\n",
    "                    data_dict[key] = torch.tensor(\n",
    "                        features[:, start:start+n_features],\n",
    "                        dtype=value.dtype\n",
    "                    )\n",
    "                    start += n_features\n",
    "                    \n",
    "        # Add edge information\n",
    "        data_dict['edge_index'] = self.graph_elements.get('edge_index')\n",
    "        data_dict['edge_attr'] = self.graph_elements.get('edge_attr')\n",
    "        \n",
    "        return Data(**data_dict)\n",
    "        \n",
    "    def _visualize_shap_results(self, shap_values: np.ndarray, molecule_idx: int):\n",
    "        \"\"\"Create visualizations for SHAP analysis\"\"\"\n",
    "        # Feature importance plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values,\n",
    "            features=self._create_feature_matrix(self.graph_data[molecule_idx]),\n",
    "            feature_names=self.feature_names,\n",
    "            show=False\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'xai_analysis/shap/molecule_{molecule_idx}_importance.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def _visualize_lime_results(self, explanation, molecule_idx: int):\n",
    "        \"\"\"Create visualizations for LIME results\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        explanation.as_pyplot_figure()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'xai_analysis/lime/molecule_{molecule_idx}_explanation.png')\n",
    "        plt.close()\n",
    "\n",
    "def debug_data_structure(embedding_path):\n",
    "    \"\"\"Debug the structure of saved embeddings\"\"\"\n",
    "    with open(embedding_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        print(\"\\nData keys:\", data.keys())\n",
    "        print(\"\\nType of embeddings:\", type(data['embeddings']))\n",
    "        print(\"Shape of embeddings:\", data['embeddings'].shape)\n",
    "        print(\"\\nType of labels:\", type(data['labels']))\n",
    "        print(\"First label:\", data['labels'][0])\n",
    "        print(\"Type of first label:\", type(data['labels'][0]))\n",
    "        if isinstance(data['labels'][0], tuple):\n",
    "            print(\"\\nTuple contents:\")\n",
    "            for i, item in enumerate(data['labels'][0]):\n",
    "                print(f\"Item {i}:\", type(item))\n",
    "                print(f\"Value: {item}\")\n",
    "                \n",
    "def main():\n",
    "    \"\"\"Run XAI analysis\"\"\"\n",
    "    try:\n",
    "        # Enable debugging output\n",
    "        debug_data_structure('./embeddings/final_embeddings_20250216_111005.pkl')\n",
    "        \n",
    "        # Initialize analyzer\n",
    "        analyzer = MolecularXAIAnalyzer(\n",
    "            encoder_path='./checkpoints/encoders/final_encoder_20250216_111050.pt',\n",
    "            embedding_path='./embeddings/final_embeddings_20250216_111005.pkl'\n",
    "        )\n",
    "        \n",
    "        # Analyze first few molecules\n",
    "        for idx in range(3):\n",
    "            print(f\"\\nAnalyzing molecule {idx}...\")\n",
    "            \n",
    "            # SHAP analysis\n",
    "            print(\"Running SHAP analysis...\")\n",
    "            shap_results = analyzer.analyze_molecular_features_shap(idx)\n",
    "            \n",
    "            # Print top features\n",
    "            print(\"\\nTop 5 important features (SHAP):\")\n",
    "            importance = shap_results['feature_importance']\n",
    "            feature_names = shap_results['feature_names']\n",
    "            top_indices = np.argsort(importance)[-5:]\n",
    "            for i in top_indices:\n",
    "                print(f\"{feature_names[i]}: {importance[i]:.4f}\")\n",
    "            \n",
    "            # LIME analysis\n",
    "            print(\"\\nRunning LIME analysis...\")\n",
    "            lime_results = analyzer.analyze_embedding_lime(idx)\n",
    "            \n",
    "            print(\"\\nTop 5 important features (LIME):\")\n",
    "            weights = lime_results['feature_weights']\n",
    "            sorted_weights = sorted(weights.items(), key=lambda x: abs(x[1]))[-5:]\n",
    "            for feature, weight in sorted_weights:\n",
    "                print(f\"{feature}: {weight:.4f}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
