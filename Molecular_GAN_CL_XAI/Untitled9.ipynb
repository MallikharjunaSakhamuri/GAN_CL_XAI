{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a366fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff158b62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MolecularEmbeddingVisualizer' object has no attribute 'analyze_embedding_property_correlations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 650\u001b[0m\n\u001b[0;32m    645\u001b[0m     visualizer\u001b[38;5;241m.\u001b[39manalyze_embedding_property_correlations(before_prefix, after_prefix, embedding_before, embedding_after)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     \u001b[43mrun_visualization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbefore_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./analysis/before_training_20250301_140313\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mafter_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./analysis/after_training_20250301_140344\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./visualizations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./embeddings/before_training_20250301_140313.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./embeddings/after_training_20250301_140344.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 645\u001b[0m, in \u001b[0;36mrun_visualization\u001b[1;34m(before_prefix, after_prefix, output_dir, embedding_before, embedding_after)\u001b[0m\n\u001b[0;32m    640\u001b[0m     visualizer \u001b[38;5;241m=\u001b[39m MolecularEmbeddingVisualizer(output_dir\u001b[38;5;241m=\u001b[39moutput_dir)\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m#     visualizer.generate_comprehensive_report(\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m#         before_prefix, after_prefix, embedding_before, embedding_after\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m     \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_embedding_property_correlations\u001b[49m(before_prefix, after_prefix, embedding_before, embedding_after)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MolecularEmbeddingVisualizer' object has no attribute 'analyze_embedding_property_correlations'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem, Descriptors\n",
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import ttest_ind, pearsonr\n",
    "\n",
    "class MolecularEmbeddingVisualizer:\n",
    "    \"\"\"Visualize and compare embeddings before and after training\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir='./visualizations'):\n",
    "        \"\"\"Initialize visualizer\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save visualizations\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Set up nice color schemes\n",
    "        self.colors = {\n",
    "            'before': '#1f77b4',  # blue\n",
    "            'after': '#ff7f0e',   # orange\n",
    "            'diff': '#2ca02c'     # green\n",
    "        }\n",
    "        \n",
    "        # Set up seaborn style\n",
    "        sns.set_style('whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.size': 12,\n",
    "            'axes.labelsize': 14,\n",
    "            'axes.titlesize': 16,\n",
    "            'xtick.labelsize': 12,\n",
    "            'ytick.labelsize': 12,\n",
    "            'legend.fontsize': 12,\n",
    "            'figure.titlesize': 18\n",
    "        })\n",
    "    \n",
    "    def load_analysis_data(self, before_prefix, after_prefix):\n",
    "        \"\"\"Load analysis data from CSV files\n",
    "        \n",
    "        Args:\n",
    "            before_prefix: Prefix for before training files (without _properties.csv)\n",
    "            after_prefix: Prefix for after training files (without _properties.csv)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of DataFrames with loaded data\n",
    "        \"\"\"\n",
    "        # Load properties\n",
    "        before_props = pd.read_csv(f\"{before_prefix}_properties.csv\", index_col=0)\n",
    "        after_props = pd.read_csv(f\"{after_prefix}_properties.csv\", index_col=0)\n",
    "        \n",
    "        # Load features\n",
    "        before_features = pd.read_csv(f\"{before_prefix}_features.csv\", index_col=0)\n",
    "        after_features = pd.read_csv(f\"{after_prefix}_features.csv\", index_col=0)\n",
    "        \n",
    "        # Load functional groups\n",
    "        before_funcs = pd.read_csv(f\"{before_prefix}_functional_groups.csv\", index_col=0)\n",
    "        after_funcs = pd.read_csv(f\"{after_prefix}_functional_groups.csv\", index_col=0)\n",
    "        \n",
    "        # Load embeddings if available\n",
    "        before_embeddings = None\n",
    "        after_embeddings = None\n",
    "        \n",
    "        try:\n",
    "            before_emb_file = f\"{before_prefix.replace('_properties', '')}.npz\"\n",
    "            if os.path.exists(before_emb_file):\n",
    "                before_data = np.load(before_emb_file)\n",
    "                before_embeddings = before_data['embeddings']\n",
    "                before_smiles = before_data['smiles']\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading before embeddings: {e}\")\n",
    "        \n",
    "        try:\n",
    "            after_emb_file = f\"{after_prefix.replace('_properties', '')}.npz\"\n",
    "            if os.path.exists(after_emb_file):\n",
    "                after_data = np.load(after_emb_file)\n",
    "                after_embeddings = after_data['embeddings']\n",
    "                after_smiles = after_data['smiles']\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading after embeddings: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'before_props': before_props,\n",
    "            'after_props': after_props,\n",
    "            'before_features': before_features,\n",
    "            'after_features': after_features,\n",
    "            'before_funcs': before_funcs,\n",
    "            'after_funcs': after_funcs,\n",
    "            'before_embeddings': before_embeddings,\n",
    "            'after_embeddings': after_embeddings\n",
    "        }\n",
    "    \n",
    "    def compare_properties_distributions(self, before_props, after_props, \n",
    "                                        props_to_compare=None, figsize=(16, 14)):\n",
    "        \"\"\"Compare molecular property distributions before and after training\n",
    "        \n",
    "        Args:\n",
    "            before_props: DataFrame with properties before training\n",
    "            after_props: DataFrame with properties after training\n",
    "            props_to_compare: List of properties to compare (default: MW, LogP, TPSA)\n",
    "            figsize: Figure size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            Figure with property distributions\n",
    "        \"\"\"\n",
    "        if props_to_compare is None:\n",
    "            props_to_compare = ['MW', 'LogP', 'TPSA', 'NumRotatableBonds', 'NumHeavyAtoms']\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create grid layout\n",
    "        nrows = (len(props_to_compare) + 1) // 2\n",
    "        gs = gridspec.GridSpec(nrows, 2, figure=fig)\n",
    "        \n",
    "        # Plot each property\n",
    "        for i, prop in enumerate(props_to_compare):\n",
    "            if prop in before_props.columns and prop in after_props.columns:\n",
    "                ax = fig.add_subplot(gs[i // 2, i % 2])\n",
    "                \n",
    "                # Get data\n",
    "                before_data = before_props[prop].dropna()\n",
    "                after_data = after_props[prop].dropna()\n",
    "                \n",
    "                # Histogram for before training\n",
    "                sns.histplot(before_data, ax=ax, color=self.colors['before'], \n",
    "                            alpha=0.6, label='Before Training', kde=True)\n",
    "                \n",
    "                # Histogram for after training\n",
    "                sns.histplot(after_data, ax=ax, color=self.colors['after'], \n",
    "                            alpha=0.6, label='After Training', kde=True)\n",
    "                \n",
    "                # Set labels\n",
    "                ax.set_title(f\"{prop} Distribution\")\n",
    "                ax.set_xlabel(prop)\n",
    "                ax.set_ylabel(\"Count\")\n",
    "                ax.legend()\n",
    "                \n",
    "                # Add p-value if enough data\n",
    "                if len(before_data) > 1 and len(after_data) > 1:\n",
    "                    # Run t-test\n",
    "                    tstat, pval = ttest_ind(before_data, after_data, equal_var=False)\n",
    "                    ax.annotate(f\"p-value: {pval:.4f}\", xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                               bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, \"property_distributions.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Property distribution comparison saved to {fig_path}\")\n",
    "        return fig\n",
    "    \n",
    "    def compare_feature_prevalence(self, before_features, after_features, figsize=(14, 8)):\n",
    "        \"\"\"Compare structural feature prevalence before and after training\n",
    "        \n",
    "        Args:\n",
    "            before_features: DataFrame with features before training\n",
    "            after_features: DataFrame with features after training\n",
    "            figsize: Figure size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            Figure with feature prevalence\n",
    "        \"\"\"\n",
    "        # Get common feature columns\n",
    "        common_features = list(set(before_features.columns) & set(after_features.columns))\n",
    "        \n",
    "        # Calculate prevalence (as percentage)\n",
    "        before_prev = before_features[common_features].mean() * 100\n",
    "        after_prev = after_features[common_features].mean() * 100\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        prev_df = pd.DataFrame({\n",
    "            'Before': before_prev,\n",
    "            'After': after_prev\n",
    "        })\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot\n",
    "        prev_df.plot(kind='bar', ax=ax, color=[self.colors['before'], self.colors['after']])\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_title(\"Structural Feature Prevalence\")\n",
    "        ax.set_ylabel(\"Prevalence (%)\")\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        # Add value labels\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.1f%%', fontsize=10)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, \"feature_prevalence.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Feature prevalence comparison saved to {fig_path}\")\n",
    "        return fig\n",
    "    \n",
    "    def compare_functional_groups(self, before_funcs, after_funcs, figsize=(14, 8)):\n",
    "        \"\"\"Compare functional group distributions before and after training\n",
    "        \n",
    "        Args:\n",
    "            before_funcs: DataFrame with functional groups before training\n",
    "            after_funcs: DataFrame with functional groups after training\n",
    "            figsize: Figure size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            Figure with functional group distributions\n",
    "        \"\"\"\n",
    "        # Get common functional group columns\n",
    "        common_funcs = list(set(before_funcs.columns) & set(after_funcs.columns))\n",
    "        \n",
    "        # Calculate average counts\n",
    "        before_avg = before_funcs[common_funcs].mean()\n",
    "        after_avg = after_funcs[common_funcs].mean()\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        func_df = pd.DataFrame({\n",
    "            'Before': before_avg,\n",
    "            'After': after_avg\n",
    "        })\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot\n",
    "        func_df.plot(kind='bar', ax=ax, color=[self.colors['before'], self.colors['after']])\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_title(\"Average Functional Group Counts\")\n",
    "        ax.set_ylabel(\"Average Count per Molecule\")\n",
    "        \n",
    "        # Add value labels\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.2f', fontsize=10)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, \"functional_group_counts.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Functional group count comparison saved to {fig_path}\")\n",
    "        return fig\n",
    "    \n",
    "    def analyze_embedding_differences(self, before_emb, after_emb, before_props, after_props,\n",
    "                                    prop_of_interest='LogP', figsize=(16, 8)):\n",
    "        \"\"\"Analyze differences in embeddings and their relationship to properties\n",
    "        \n",
    "        Args:\n",
    "            before_emb: Embeddings before training\n",
    "            after_emb: Embeddings after training\n",
    "            before_props: DataFrame with properties before training\n",
    "            after_props: DataFrame with properties after training\n",
    "            prop_of_interest: Property to color points by\n",
    "            figsize: Figure size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            Figure with embedding analysis\n",
    "        \"\"\"\n",
    "        if before_emb is None or after_emb is None:\n",
    "            print(\"Embeddings not available for analysis\")\n",
    "            return None\n",
    "        \n",
    "        # Make sure we have the same number of embeddings\n",
    "        if len(before_emb) != len(after_emb):\n",
    "            # Take the smaller size\n",
    "            min_size = min(len(before_emb), len(after_emb))\n",
    "            before_emb = before_emb[:min_size]\n",
    "            after_emb = after_emb[:min_size]\n",
    "            before_props = before_props.iloc[:min_size]\n",
    "            after_props = after_props.iloc[:min_size]\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # Apply PCA to both embeddings\n",
    "        pca = PCA(n_components=2)\n",
    "        before_pca = pca.fit_transform(before_emb)\n",
    "        after_pca = pca.fit_transform(after_emb)\n",
    "        \n",
    "        # Get property for coloring\n",
    "        if prop_of_interest in before_props.columns:\n",
    "            prop_values = before_props[prop_of_interest].values\n",
    "            vmin, vmax = np.percentile(prop_values, [5, 95])\n",
    "            \n",
    "            # Plot before training\n",
    "            sc1 = axes[0].scatter(before_pca[:, 0], before_pca[:, 1], \n",
    "                                c=prop_values, cmap='viridis', alpha=0.8,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "            axes[0].set_title(f\"Before Training (PCA)\")\n",
    "            axes[0].set_xlabel(\"PC1\")\n",
    "            axes[0].set_ylabel(\"PC2\")\n",
    "            \n",
    "            # Plot after training\n",
    "            sc2 = axes[1].scatter(after_pca[:, 0], after_pca[:, 1], \n",
    "                                c=prop_values, cmap='viridis', alpha=0.8,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "            axes[1].set_title(f\"After Training (PCA)\")\n",
    "            axes[1].set_xlabel(\"PC1\")\n",
    "            axes[1].set_ylabel(\"PC2\")\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(sc1, ax=axes)\n",
    "            cbar.set_label(prop_of_interest)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, f\"embedding_pca_{prop_of_interest}.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Embedding PCA analysis saved to {fig_path}\")\n",
    "        return fig\n",
    "    \n",
    "    def property_bias_analysis(self, before_props, after_props, before_emb, after_emb, \n",
    "                              props_to_analyze=None, figsize=(16, 12)):\n",
    "        \"\"\"Analyze bias in embedding space with respect to molecular properties\n",
    "        \n",
    "        Args:\n",
    "            before_props: DataFrame with properties before training\n",
    "            after_props: DataFrame with properties after training\n",
    "            before_emb: Embeddings before training\n",
    "            after_emb: Embeddings after training\n",
    "            props_to_analyze: List of properties to analyze\n",
    "            figsize: Figure size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            Figure with property bias analysis\n",
    "        \"\"\"\n",
    "        if before_emb is None or after_emb is None:\n",
    "            print(\"Embeddings not available for analysis\")\n",
    "            return None\n",
    "        \n",
    "        if props_to_analyze is None:\n",
    "            props_to_analyze = ['MW', 'LogP', 'TPSA', 'NumHAcceptors', 'NumHDonors']\n",
    "        \n",
    "        # Make sure properties are in both DataFrames\n",
    "        props_to_analyze = [p for p in props_to_analyze \n",
    "                          if p in before_props.columns and p in after_props.columns]\n",
    "        \n",
    "        # Apply PCA to before and after embeddings\n",
    "        pca_before = PCA(n_components=10)\n",
    "        pca_after = PCA(n_components=10)\n",
    "        \n",
    "        before_pca = pca_before.fit_transform(before_emb)\n",
    "        after_pca = pca_after.fit_transform(after_emb)\n",
    "        \n",
    "        # Calculate correlations between PCA components and properties\n",
    "        before_corrs = []\n",
    "        after_corrs = []\n",
    "        \n",
    "        for prop in props_to_analyze:\n",
    "            before_prop_vals = before_props[prop].values\n",
    "            after_prop_vals = after_props[prop].values\n",
    "            \n",
    "            # Correlations with before training PCA components\n",
    "            before_prop_corrs = [pearsonr(before_pca[:, i], before_prop_vals)[0] \n",
    "                               for i in range(before_pca.shape[1])]\n",
    "            \n",
    "            # Correlations with after training PCA components\n",
    "            after_prop_corrs = [pearsonr(after_pca[:, i], after_prop_vals)[0] \n",
    "                              for i in range(after_pca.shape[1])]\n",
    "            \n",
    "            before_corrs.append(before_prop_corrs)\n",
    "            after_corrs.append(after_prop_corrs)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(len(props_to_analyze), 1, figsize=figsize)\n",
    "        if len(props_to_analyze) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Plot correlations for each property\n",
    "        for i, prop in enumerate(props_to_analyze):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Bar plot of correlations\n",
    "            x = np.arange(len(before_corrs[i]))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax.bar(x - width/2, np.abs(before_corrs[i]), width, label='Before Training',\n",
    "                  color=self.colors['before'])\n",
    "            ax.bar(x + width/2, np.abs(after_corrs[i]), width, label='After Training',\n",
    "                  color=self.colors['after'])\n",
    "            \n",
    "            # Set labels\n",
    "            ax.set_title(f\"Correlation of PCA Components with {prop}\")\n",
    "            ax.set_xlabel(\"PCA Component\")\n",
    "            ax.set_ylabel(\"|Correlation|\")\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([f\"PC{j+1}\" for j in range(len(before_corrs[i]))])\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add correlation values\n",
    "            for j, (b_corr, a_corr) in enumerate(zip(before_corrs[i], after_corrs[i])):\n",
    "                ax.annotate(f\"{b_corr:.2f}\", xy=(j - width/2, np.abs(b_corr) + 0.02), \n",
    "                          ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "                ax.annotate(f\"{a_corr:.2f}\", xy=(j + width/2, np.abs(a_corr) + 0.02), \n",
    "                          ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, \"property_bias_analysis.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Property bias analysis saved to {fig_path}\")\n",
    "        return fig\n",
    "    \n",
    "    def analyze_correlations(self, before_props, after_props):\n",
    "        \"\"\"Analyze correlations between properties before and after training\n",
    "        \n",
    "        Args:\n",
    "            before_props: DataFrame with properties before training\n",
    "            after_props: DataFrame with properties after training\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with correlation changes\n",
    "        \"\"\"\n",
    "        # Get common property columns (excluding non-numeric)\n",
    "        common_props = []\n",
    "        for col in before_props.columns:\n",
    "            if col in after_props.columns:\n",
    "                if np.issubdtype(before_props[col].dtype, np.number) and np.issubdtype(after_props[col].dtype, np.number):\n",
    "                    common_props.append(col)\n",
    "        \n",
    "        # Calculate correlations\n",
    "        before_corr = before_props[common_props].corr()\n",
    "        after_corr = after_props[common_props].corr()\n",
    "        \n",
    "        # Calculate correlation differences\n",
    "        corr_diff = after_corr - before_corr\n",
    "        \n",
    "        # Create figure with three subplots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "        \n",
    "        # Plot before correlations\n",
    "        sns.heatmap(before_corr, ax=axes[0], cmap='coolwarm', vmin=-1, vmax=1, \n",
    "                  annot=True, fmt='.2f', square=True, cbar=True)\n",
    "        axes[0].set_title(\"Property Correlations Before Training\")\n",
    "        \n",
    "        # Plot after correlations\n",
    "        sns.heatmap(after_corr, ax=axes[1], cmap='coolwarm', vmin=-1, vmax=1, \n",
    "                  annot=True, fmt='.2f', square=True, cbar=True)\n",
    "        axes[1].set_title(\"Property Correlations After Training\")\n",
    "        \n",
    "        # Plot correlation differences\n",
    "        sns.heatmap(corr_diff, ax=axes[2], cmap='coolwarm', vmin=-0.5, vmax=0.5, \n",
    "                  annot=True, fmt='.2f', square=True, cbar=True)\n",
    "        axes[2].set_title(\"Correlation Changes (After - Before)\")\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(self.output_dir, \"property_correlations.png\")\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Property correlation analysis saved to {fig_path}\")\n",
    "        \n",
    "        return corr_diff\n",
    "    \n",
    "    def generate_comprehensive_report(self, before_prefix, after_prefix, embedding_before=None, embedding_after=None):\n",
    "        \"\"\"Generate a comprehensive report with all analyses\n",
    "        \n",
    "        Args:\n",
    "            before_prefix: Prefix for before training files (without _properties.csv)\n",
    "            after_prefix: Prefix for after training files (without _properties.csv)\n",
    "            embedding_before: Path to before training embeddings (optional)\n",
    "            embedding_after: Path to after training embeddings (optional)\n",
    "            \n",
    "        Returns:\n",
    "            None (all figures saved to output_dir)\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        data = self.load_analysis_data(before_prefix, after_prefix)\n",
    "        \n",
    "        # Try to load embeddings if provided\n",
    "        before_embeddings = data['before_embeddings']\n",
    "        after_embeddings = data['after_embeddings']\n",
    "        \n",
    "        if embedding_before is not None and before_embeddings is None:\n",
    "            try:\n",
    "                before_data = np.load(embedding_before)\n",
    "                before_embeddings = before_data['embeddings']\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading before embeddings: {e}\")\n",
    "        \n",
    "        if embedding_after is not None and after_embeddings is None:\n",
    "            try:\n",
    "                after_data = np.load(embedding_after)\n",
    "                after_embeddings = after_data['embeddings']\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading after embeddings: {e}\")\n",
    "        \n",
    "        # Generate visualizations\n",
    "        print(\"\\nGenerating property distribution comparison...\")\n",
    "        self.compare_properties_distributions(\n",
    "            data['before_props'], data['after_props'],\n",
    "            props_to_compare=['MW', 'LogP', 'TPSA', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nGenerating feature prevalence comparison...\")\n",
    "        self.compare_feature_prevalence(\n",
    "            data['before_features'], data['after_features']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nGenerating functional group comparison...\")\n",
    "        self.compare_functional_groups(\n",
    "            data['before_funcs'], data['after_funcs']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nGenerating property correlation analysis...\")\n",
    "        self.analyze_correlations(\n",
    "            data['before_props'], data['after_props']\n",
    "        )\n",
    "        \n",
    "        if before_embeddings is not None and after_embeddings is not None:\n",
    "            print(\"\\nGenerating embedding analysis for LogP...\")\n",
    "            self.analyze_embedding_differences(\n",
    "                before_embeddings, after_embeddings,\n",
    "                data['before_props'], data['after_props'],\n",
    "                prop_of_interest='LogP'\n",
    "            )\n",
    "            \n",
    "            print(\"\\nGenerating embedding analysis for MW...\")\n",
    "            self.analyze_embedding_differences(\n",
    "                before_embeddings, after_embeddings,\n",
    "                data['before_props'], data['after_props'],\n",
    "                prop_of_interest='MW'\n",
    "            )\n",
    "            \n",
    "            print(\"\\nGenerating property bias analysis...\")\n",
    "            self.property_bias_analysis(\n",
    "                data['before_props'], data['after_props'],\n",
    "                before_embeddings, after_embeddings\n",
    "            )\n",
    "        \n",
    "        print(f\"\\nAll visualizations saved to {self.output_dir}\")\n",
    "\n",
    "        \n",
    "def analyze_embedding_property_correlations(self, before_emb, after_emb, properties_df, \n",
    "                                           props_to_analyze=None):\n",
    "    \"\"\"Analyze how properties correlate with embedding dimensions\n",
    "    \n",
    "    Args:\n",
    "        before_emb: Embeddings before training\n",
    "        after_emb: Embeddings after training\n",
    "        properties_df: DataFrame with molecular properties\n",
    "        props_to_analyze: List of properties to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Figure showing correlation changes\n",
    "    \"\"\"\n",
    "    if props_to_analyze is None:\n",
    "        props_to_analyze = ['MW', 'LogP', 'TPSA', 'NumHAcceptors', 'NumHDonors']\n",
    "    \n",
    "    # Select top principal components\n",
    "    pca = PCA(n_components=5)\n",
    "    before_pca = pca.fit_transform(before_emb)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    after_pca = pca.fit_transform(after_emb)\n",
    "    \n",
    "    # Calculate correlations between properties and PCA components\n",
    "    before_correlations = {}\n",
    "    after_correlations = {}\n",
    "    \n",
    "    for prop in props_to_analyze:\n",
    "        if prop in properties_df.columns:\n",
    "            prop_values = properties_df[prop].values\n",
    "            \n",
    "            before_corrs = []\n",
    "            after_corrs = []\n",
    "            \n",
    "            for i in range(5):  # For top 5 PCA components\n",
    "                before_corr = np.abs(np.corrcoef(before_pca[:, i], prop_values)[0, 1])\n",
    "                after_corr = np.abs(np.corrcoef(after_pca[:, i], prop_values)[0, 1])\n",
    "                \n",
    "                before_corrs.append(before_corr)\n",
    "                after_corrs.append(after_corr)\n",
    "            \n",
    "            before_correlations[prop] = before_corrs\n",
    "            after_correlations[prop] = after_corrs\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(len(props_to_analyze), 1, figsize=(12, 3*len(props_to_analyze)))\n",
    "    \n",
    "    for i, prop in enumerate(props_to_analyze):\n",
    "        if prop in before_correlations:\n",
    "            ax = axes[i] if len(props_to_analyze) > 1 else axes\n",
    "            \n",
    "            x = np.arange(5)\n",
    "            width = 0.35\n",
    "            \n",
    "            ax.bar(x - width/2, before_correlations[prop], width, label='Before Training')\n",
    "            ax.bar(x + width/2, after_correlations[prop], width, label='After Training')\n",
    "            \n",
    "            ax.set_title(f\"Correlation with {prop}\")\n",
    "            ax.set_xlabel(\"PCA Component\")\n",
    "            ax.set_ylabel(\"Absolute Correlation\")\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([f\"PC{j+1}\" for j in range(5)])\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig        \n",
    "\n",
    "def run_visualization(before_prefix, after_prefix, output_dir='./visualizations',\n",
    "                     embedding_before=None, embedding_after=None):\n",
    "    \"\"\"Run visualization pipeline\n",
    "    \n",
    "    Args:\n",
    "        before_prefix: Prefix for before training files (without _properties.csv)\n",
    "        after_prefix: Prefix for after training files (without _properties.csv)\n",
    "        output_dir: Directory to save visualizations\n",
    "        embedding_before: Path to before training embeddings (optional)\n",
    "        embedding_after: Path to after training embeddings (optional)\n",
    "        \n",
    "    Returns:\n",
    "        None (all figures saved to output_dir)\n",
    "    \"\"\"\n",
    "    visualizer = MolecularEmbeddingVisualizer(output_dir=output_dir)\n",
    "    visualizer.generate_comprehensive_report(\n",
    "        before_prefix, after_prefix, embedding_before, embedding_after\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    run_visualization(\n",
    "        before_prefix=\"./analysis/before_training_20250301_140313\",\n",
    "        after_prefix=\"./analysis/after_training_20250301_140344\",\n",
    "        output_dir=\"./visualizations\",\n",
    "        embedding_before=\"./embeddings/before_training_20250301_140313.npz\",\n",
    "        embedding_after=\"./embeddings/after_training_20250301_140344.npz\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0181ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_embedding_property_correlations(self, before_emb, after_emb, properties_df, \n",
    "                                           props_to_analyze=None):\n",
    "    \"\"\"Analyze how properties correlate with embedding dimensions\n",
    "    \n",
    "    Args:\n",
    "        before_emb: Embeddings before training\n",
    "        after_emb: Embeddings after training\n",
    "        properties_df: DataFrame with molecular properties\n",
    "        props_to_analyze: List of properties to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Figure showing correlation changes\n",
    "    \"\"\"\n",
    "    if props_to_analyze is None:\n",
    "        props_to_analyze = ['MW', 'LogP', 'TPSA', 'NumHAcceptors', 'NumHDonors']\n",
    "    \n",
    "    # Select top principal components\n",
    "    pca = PCA(n_components=5)\n",
    "    before_pca = pca.fit_transform(before_emb)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    after_pca = pca.fit_transform(after_emb)\n",
    "    \n",
    "    # Calculate correlations between properties and PCA components\n",
    "    before_correlations = {}\n",
    "    after_correlations = {}\n",
    "    \n",
    "    for prop in props_to_analyze:\n",
    "        if prop in properties_df.columns:\n",
    "            prop_values = properties_df[prop].values\n",
    "            \n",
    "            before_corrs = []\n",
    "            after_corrs = []\n",
    "            \n",
    "            for i in range(5):  # For top 5 PCA components\n",
    "                before_corr = np.abs(np.corrcoef(before_pca[:, i], prop_values)[0, 1])\n",
    "                after_corr = np.abs(np.corrcoef(after_pca[:, i], prop_values)[0, 1])\n",
    "                \n",
    "                before_corrs.append(before_corr)\n",
    "                after_corrs.append(after_corr)\n",
    "            \n",
    "            before_correlations[prop] = before_corrs\n",
    "            after_correlations[prop] = after_corrs\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(len(props_to_analyze), 1, figsize=(12, 3*len(props_to_analyze)))\n",
    "    \n",
    "    for i, prop in enumerate(props_to_analyze):\n",
    "        if prop in before_correlations:\n",
    "            ax = axes[i] if len(props_to_analyze) > 1 else axes\n",
    "            \n",
    "            x = np.arange(5)\n",
    "            width = 0.35\n",
    "            \n",
    "            ax.bar(x - width/2, before_correlations[prop], width, label='Before Training')\n",
    "            ax.bar(x + width/2, after_correlations[prop], width, label='After Training')\n",
    "            \n",
    "            ax.set_title(f\"Correlation with {prop}\")\n",
    "            ax.set_xlabel(\"PCA Component\")\n",
    "            ax.set_ylabel(\"Absolute Correlation\")\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([f\"PC{j+1}\" for j in range(5)])\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64398a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
