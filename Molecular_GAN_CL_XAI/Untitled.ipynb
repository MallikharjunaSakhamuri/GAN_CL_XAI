{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534a67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lime\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00be347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Dict\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333549b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing embeddings...\n",
      "Loading embeddings from ./embeddings/final_embeddings.pkl\n",
      "Loaded 397 embeddings of dimension 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malli\\anaconda3\\envs\\baceenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1411: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Analysis Results:\n",
      "- Number of embeddings: 397\n",
      "- Embedding dimension: 128\n",
      "- Number of clusters found: 5\n",
      "\n",
      "Analyzing encoder...\n",
      "Loading encoder from ./checkpoints/encoders/best_encoder.pt\n",
      "\n",
      "Encoder Analysis Results:\n",
      "Layer weight statistics:\n",
      "\n",
      "node_encoder.0.weight:\n",
      "  mean: -0.0033\n",
      "  std: 0.1228\n",
      "  min: -0.2614\n",
      "  max: 0.2277\n",
      "\n",
      "node_encoder.2.weight:\n",
      "  mean: 0.0006\n",
      "  std: 0.0894\n",
      "  min: -0.1946\n",
      "  max: 0.2081\n",
      "\n",
      "edge_encoder.0.weight:\n",
      "  mean: 0.0054\n",
      "  std: 0.1231\n",
      "  min: -0.2120\n",
      "  max: 0.2124\n",
      "\n",
      "edge_encoder.2.weight:\n",
      "  mean: -0.0002\n",
      "  std: 0.0884\n",
      "  min: -0.1531\n",
      "  max: 0.1531\n",
      "\n",
      "conv1.lin.weight:\n",
      "  mean: -0.0007\n",
      "  std: 0.0891\n",
      "  min: -0.1997\n",
      "  max: 0.2052\n",
      "\n",
      "conv2.lin.weight:\n",
      "  mean: -0.0014\n",
      "  std: 0.0888\n",
      "  min: -0.2155\n",
      "  max: 0.2167\n",
      "\n",
      "conv3.lin.weight:\n",
      "  mean: -0.0021\n",
      "  std: 0.0887\n",
      "  min: -0.2365\n",
      "  max: 0.2032\n",
      "\n",
      "projection.0.weight:\n",
      "  mean: -0.0013\n",
      "  std: 0.0882\n",
      "  min: -0.1954\n",
      "  max: 0.2025\n",
      "\n",
      "projection.2.weight:\n",
      "  mean: -0.0005\n",
      "  std: 0.0884\n",
      "  min: -0.2278\n",
      "  max: 0.2516\n",
      "\n",
      "Analysis complete! Visualizations saved in:\n",
      "- embedding_analysis/\n",
      "- encoder_analysis/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EmbeddingAnalyzer:\n",
    "    \"\"\"Analyzer for the learned embeddings\"\"\"\n",
    "    def __init__(self, embedding_path: str):\n",
    "        \"\"\"Load and analyze saved embeddings\"\"\"\n",
    "        if not os.path.exists(embedding_path):\n",
    "            raise FileNotFoundError(f\"Embedding file not found: {embedding_path}\")\n",
    "            \n",
    "        print(f\"Loading embeddings from {embedding_path}\")\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.embeddings = data['embeddings']\n",
    "            self.graphs = data['labels']\n",
    "            \n",
    "        print(f\"Loaded {len(self.embeddings)} embeddings of dimension {self.embeddings.shape[1]}\")\n",
    "        \n",
    "    def analyze_embedding_space(self) -> Dict:\n",
    "        \"\"\"Analyze the learned embedding space\"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs('embedding_analysis', exist_ok=True)\n",
    "        \n",
    "        # 1. Dimensionality Analysis\n",
    "        embedding_dim = self.embeddings.shape[1]\n",
    "        dim_variances = np.var(self.embeddings, axis=0)\n",
    "        \n",
    "        # Plot dimension variances\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=list(range(embedding_dim)), y=dim_variances)\n",
    "        plt.title('Variance in Each Embedding Dimension')\n",
    "        plt.xlabel('Dimension')\n",
    "        plt.ylabel('Variance')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('embedding_analysis/dimension_variances.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Clustering Analysis\n",
    "        from sklearn.cluster import KMeans\n",
    "        kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "        clusters = kmeans.fit_predict(self.embeddings)\n",
    "        \n",
    "        # 3. t-SNE Visualization\n",
    "        from sklearn.manifold import TSNE\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        embeddings_2d = tsne.fit_transform(self.embeddings)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                            c=clusters, cmap='viridis', alpha=0.6)\n",
    "        plt.colorbar(scatter)\n",
    "        plt.title('t-SNE Visualization of Embedding Space\\nColored by Clusters')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('embedding_analysis/tsne_visualization.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. Correlation Analysis\n",
    "        correlation_matrix = np.corrcoef(self.embeddings.T)\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        sns.heatmap(correlation_matrix, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Between Embedding Dimensions')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('embedding_analysis/dimension_correlations.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return {\n",
    "            'dimension_stats': {\n",
    "                'mean': np.mean(self.embeddings, axis=0),\n",
    "                'std': np.std(self.embeddings, axis=0),\n",
    "                'variances': dim_variances\n",
    "            },\n",
    "            'clustering': {\n",
    "                'cluster_labels': clusters,\n",
    "                'cluster_centers': kmeans.cluster_centers_\n",
    "            },\n",
    "            'tsne_coords': embeddings_2d,\n",
    "            'correlation_matrix': correlation_matrix\n",
    "        }\n",
    "\n",
    "class EncoderAnalyzer:\n",
    "    \"\"\"Analyzer for the encoder weights\"\"\"\n",
    "    def __init__(self, encoder_path: str):\n",
    "        \"\"\"Load and analyze saved encoder\"\"\"\n",
    "        if not os.path.exists(encoder_path):\n",
    "            raise FileNotFoundError(f\"Encoder file not found: {encoder_path}\")\n",
    "            \n",
    "        print(f\"Loading encoder from {encoder_path}\")\n",
    "        checkpoint = torch.load(encoder_path, map_location='cpu')\n",
    "        self.state_dict = checkpoint['encoder_state_dict']\n",
    "        self.model_info = checkpoint.get('model_info', {})\n",
    "        \n",
    "    def analyze_weights(self) -> Dict:\n",
    "        \"\"\"Analyze the learned weights of the encoder\"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs('encoder_analysis', exist_ok=True)\n",
    "        \n",
    "        weight_stats = {}\n",
    "        for name, param in self.state_dict.items():\n",
    "            if 'weight' in name:\n",
    "                # Convert to numpy for analysis\n",
    "                weights = param.cpu().numpy()\n",
    "                \n",
    "                # Calculate statistics\n",
    "                weight_stats[name] = {\n",
    "                    'mean': float(np.mean(weights)),\n",
    "                    'std': float(np.std(weights)),\n",
    "                    'min': float(np.min(weights)),\n",
    "                    'max': float(np.max(weights))\n",
    "                }\n",
    "                \n",
    "                # Plot weight distribution\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.histplot(weights.flatten(), bins=50)\n",
    "                plt.title(f'Weight Distribution for {name}')\n",
    "                plt.xlabel('Weight Value')\n",
    "                plt.ylabel('Count')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'encoder_analysis/{name}_distribution.png')\n",
    "                plt.close()\n",
    "        \n",
    "        return weight_stats\n",
    "\n",
    "def main():\n",
    "    \"\"\"Analyze saved embeddings and encoder\"\"\"\n",
    "    # Paths to saved files\n",
    "    EMBEDDING_PATH = './embeddings/final_embeddings.pkl'\n",
    "    ENCODER_PATH = './checkpoints/encoders/best_encoder.pt'\n",
    "    \n",
    "    try:\n",
    "        # 1. Analyze Embeddings\n",
    "        print(\"\\nAnalyzing embeddings...\")\n",
    "        embedding_analyzer = EmbeddingAnalyzer(EMBEDDING_PATH)\n",
    "        embedding_results = embedding_analyzer.analyze_embedding_space()\n",
    "        \n",
    "        print(\"\\nEmbedding Analysis Results:\")\n",
    "        print(f\"- Number of embeddings: {len(embedding_analyzer.embeddings)}\")\n",
    "        print(f\"- Embedding dimension: {embedding_analyzer.embeddings.shape[1]}\")\n",
    "        print(f\"- Number of clusters found: {len(np.unique(embedding_results['clustering']['cluster_labels']))}\")\n",
    "        \n",
    "        # 2. Analyze Encoder\n",
    "        print(\"\\nAnalyzing encoder...\")\n",
    "        encoder_analyzer = EncoderAnalyzer(ENCODER_PATH)\n",
    "        weight_stats = encoder_analyzer.analyze_weights()\n",
    "        \n",
    "        print(\"\\nEncoder Analysis Results:\")\n",
    "        print(\"Layer weight statistics:\")\n",
    "        for layer_name, stats in weight_stats.items():\n",
    "            print(f\"\\n{layer_name}:\")\n",
    "            for stat_name, value in stats.items():\n",
    "                print(f\"  {stat_name}: {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nAnalysis complete! Visualizations saved in:\")\n",
    "        print(\"- embedding_analysis/\")\n",
    "        print(\"- encoder_analysis/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
