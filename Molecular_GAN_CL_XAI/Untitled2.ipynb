{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dafeb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting molecular interpretation analysis...\n",
      "Loading encoder from ./checkpoints/encoders/best_encoder.pt\n",
      "Initializing encoder architecture...\n",
      "Model dimensions: node_dim=10, edge_dim=5\n",
      "Encoder loaded successfully\n",
      "\n",
      "Loading embeddings from ./embeddings/final_embeddings.pkl\n",
      "Loaded 49693 embeddings of dimension 128\n",
      "\n",
      "1. Analyzing embedding space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malli\\anaconda3\\envs\\baceenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Malli\\anaconda3\\envs\\baceenv\\lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Embedding space visualization saved\n",
      "\n",
      "2. Analyzing feature patterns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing SHAP values:   0%|                                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing feature patterns: 'tuple' object has no attribute 'x'\n",
      "\n",
      "Analysis complete! Results saved in 'molecular_analysis' directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shap\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import umap\n",
    "import pickle\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GraphDiscriminator(nn.Module):\n",
    "    \"\"\"Reimplementation of original discriminator architecture\"\"\"\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int = 128, output_dim: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature encoding\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "        \n",
    "        # Projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = torch.cat([data.x_cat.float(), data.x_phys], dim=-1)\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr.float()\n",
    "        batch = data.batch\n",
    "        \n",
    "        # Initial feature encoding\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Graph convolutions\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Projection\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MolecularInterpreter:\n",
    "    \"\"\"Interpreter for molecular embeddings and encoder\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_path: str, embedding_path: str):\n",
    "        \"\"\"\n",
    "        Initialize interpreter with saved model and embeddings\n",
    "        Args:\n",
    "            encoder_path: Path to saved encoder\n",
    "            embedding_path: Path to saved embeddings\n",
    "        \"\"\"\n",
    "        # Load saved checkpoint\n",
    "        print(f\"Loading encoder from {encoder_path}\")\n",
    "        checkpoint = torch.load(encoder_path, map_location='cpu')\n",
    "        \n",
    "        # Get model configuration\n",
    "        print(\"Initializing encoder architecture...\")\n",
    "        try:\n",
    "            model_info = checkpoint.get('model_info', {})\n",
    "            node_dim = model_info.get('node_dim')\n",
    "            edge_dim = model_info.get('edge_dim')\n",
    "            \n",
    "            # If dimensions not in model_info, try to infer from saved weights\n",
    "            if node_dim is None or edge_dim is None:\n",
    "                # Get first layer's weight shape\n",
    "                first_layer = next(iter(checkpoint['encoder_state_dict'].items()))\n",
    "                if 'node_encoder.0.weight' in checkpoint['encoder_state_dict']:\n",
    "                    node_dim = checkpoint['encoder_state_dict']['node_encoder.0.weight'].shape[1]\n",
    "                else:\n",
    "                    raise ValueError(\"Could not determine node_dim from saved weights\")\n",
    "                \n",
    "                if 'edge_encoder.0.weight' in checkpoint['encoder_state_dict']:\n",
    "                    edge_dim = checkpoint['encoder_state_dict']['edge_encoder.0.weight'].shape[1]\n",
    "                else:\n",
    "                    raise ValueError(\"Could not determine edge_dim from saved weights\")\n",
    "                \n",
    "            print(f\"Model dimensions: node_dim={node_dim}, edge_dim={edge_dim}\")\n",
    "            \n",
    "            # Initialize model\n",
    "            self.encoder = GraphDiscriminator(\n",
    "                node_dim=node_dim,\n",
    "                edge_dim=edge_dim,\n",
    "                hidden_dim=128,\n",
    "                output_dim=128\n",
    "            )\n",
    "            \n",
    "            # Load state dict\n",
    "            self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "            self.encoder.eval()\n",
    "            print(\"Encoder loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing encoder: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "        # Load embeddings\n",
    "        print(f\"\\nLoading embeddings from {embedding_path}\")\n",
    "        try:\n",
    "            with open(embedding_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.embeddings = data['embeddings']\n",
    "                self.graphs = data['labels']\n",
    "                \n",
    "            print(f\"Loaded {len(self.embeddings)} embeddings of dimension {self.embeddings.shape[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embeddings: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "        # Create output directory\n",
    "        os.makedirs('molecular_analysis', exist_ok=True)\n",
    "\n",
    "    def compute_atom_importance(self, graph_data) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute SHAP values for atoms in a molecule\n",
    "        Args:\n",
    "            graph_data: Molecular graph data\n",
    "        Returns:\n",
    "            Array of SHAP values per atom\n",
    "        \"\"\"\n",
    "        # Convert input to tensor if needed\n",
    "        x = torch.tensor(graph_data.x) if not isinstance(graph_data.x, torch.Tensor) else graph_data.x\n",
    "        \n",
    "        def model_fn(features):\n",
    "            with torch.no_grad():\n",
    "                # Create a new graph data object with the modified features\n",
    "                new_data = Data(\n",
    "                    x=features,\n",
    "                    edge_index=graph_data.edge_index,\n",
    "                    edge_attr=graph_data.edge_attr\n",
    "                )\n",
    "                return self.encoder(new_data)\n",
    "        \n",
    "        # Initialize SHAP explainer\n",
    "        background = torch.zeros_like(x)  # Use zero background\n",
    "        explainer = shap.GradientExplainer(model_fn, background)\n",
    "        shap_values = explainer.shap_values(x)\n",
    "        \n",
    "        # Aggregate SHAP values across features\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = np.array(shap_values).mean(axis=0)\n",
    "        atom_importance = np.abs(shap_values).mean(axis=1)\n",
    "        \n",
    "        return atom_importance\n",
    "        \n",
    "    def visualize_atom_importance(self, smiles: str, importance_values: np.ndarray,\n",
    "                                save_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Visualize atom importance on molecular structure\n",
    "        Args:\n",
    "            smiles: SMILES string of molecule\n",
    "            importance_values: SHAP values per atom\n",
    "            save_path: Path to save visualization\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(f\"Failed to parse SMILES: {smiles}\")\n",
    "                return\n",
    "                \n",
    "            # Ensure we have the right number of values\n",
    "            if len(importance_values) != mol.GetNumAtoms():\n",
    "                print(f\"Mismatch in number of atoms: {len(importance_values)} values for {mol.GetNumAtoms()} atoms\")\n",
    "                return\n",
    "            \n",
    "            # Normalize importance values to [0,1]\n",
    "            norm_values = (importance_values - importance_values.min()) / \\\n",
    "                         (importance_values.max() - importance_values.min() + 1e-9)\n",
    "            \n",
    "            # Create atom colors (red = important, blue = less important)\n",
    "            atom_colors = {\n",
    "                i: (1.0, 1.0 - v, 1.0 - v) \n",
    "                for i, v in enumerate(norm_values)\n",
    "            }\n",
    "            \n",
    "            # Draw molecule\n",
    "            img = Draw.MolToImage(\n",
    "                mol,\n",
    "                highlightAtoms=list(range(mol.GetNumAtoms())),\n",
    "                highlightAtomColors=atom_colors,\n",
    "                size=(400, 400)\n",
    "            )\n",
    "            img.save(save_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing molecule: {str(e)}\")\n",
    "\n",
    "    def analyze_embedding_space(self) -> None:\n",
    "        \"\"\"Analyze and visualize embedding space\"\"\"\n",
    "        try:\n",
    "            # Reduce dimensionality\n",
    "            reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "            embedding_2d = reducer.fit_transform(self.embeddings)\n",
    "            \n",
    "            # Plot embedding space\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(\n",
    "                embedding_2d[:, 0],\n",
    "                embedding_2d[:, 1],\n",
    "                c=np.arange(len(embedding_2d)),\n",
    "                cmap='viridis',\n",
    "                alpha=0.6\n",
    "            )\n",
    "            plt.colorbar(scatter, label='Molecule Index')\n",
    "            plt.title('Molecular Embedding Space (UMAP)')\n",
    "            plt.savefig('molecular_analysis/embedding_space.png')\n",
    "            plt.close()\n",
    "            \n",
    "            return embedding_2d\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing embedding space: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_feature_patterns(self) -> Dict:\n",
    "        \"\"\"Analyze patterns in how features influence embeddings\"\"\"\n",
    "        try:\n",
    "            # Get SHAP values for a subset of molecules\n",
    "            n_samples = min(100, len(self.graphs))\n",
    "            all_shap_values = []\n",
    "            \n",
    "            for i in tqdm(range(n_samples), desc=\"Computing SHAP values\"):\n",
    "                shap_values = self.compute_atom_importance(self.graphs[i])\n",
    "                all_shap_values.append(shap_values)\n",
    "                \n",
    "            all_shap_values = np.array(all_shap_values)\n",
    "            \n",
    "            # Analyze feature patterns\n",
    "            mean_importance = all_shap_values.mean(axis=0)\n",
    "            std_importance = all_shap_values.std(axis=0)\n",
    "            \n",
    "            # Plot feature importance distribution\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(data=all_shap_values)\n",
    "            plt.title('Distribution of Atom Importance Across Molecules')\n",
    "            plt.xlabel('Atom Index')\n",
    "            plt.ylabel('SHAP Value')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('molecular_analysis/feature_importance_distribution.png')\n",
    "            plt.close()\n",
    "            \n",
    "            return {\n",
    "                'mean_importance': mean_importance,\n",
    "                'std_importance': std_importance,\n",
    "                'all_shap_values': all_shap_values\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing feature patterns: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run molecular interpretation analysis\"\"\"\n",
    "    try:\n",
    "        print(\"Starting molecular interpretation analysis...\")\n",
    "        \n",
    "        # Check if files exist\n",
    "        encoder_path = './checkpoints/encoders/best_encoder.pt'\n",
    "        embedding_path = './embeddings/final_embeddings.pkl'\n",
    "        \n",
    "        if not os.path.exists(encoder_path):\n",
    "            raise FileNotFoundError(f\"Encoder file not found: {encoder_path}\")\n",
    "        if not os.path.exists(embedding_path):\n",
    "            raise FileNotFoundError(f\"Embedding file not found: {embedding_path}\")\n",
    "        \n",
    "        # Initialize interpreter\n",
    "        interpreter = MolecularInterpreter(encoder_path, embedding_path)\n",
    "        \n",
    "        # Run analysis steps\n",
    "        print(\"\\n1. Analyzing embedding space...\")\n",
    "        embedding_2d = interpreter.analyze_embedding_space()\n",
    "        if embedding_2d is not None:\n",
    "            print(\"   Embedding space visualization saved\")\n",
    "        \n",
    "        print(\"\\n2. Analyzing feature patterns...\")\n",
    "        feature_patterns = interpreter.analyze_feature_patterns()\n",
    "        if feature_patterns is not None:\n",
    "            print(\"   Feature patterns analysis completed\")\n",
    "        \n",
    "        print(\"\\nAnalysis complete! Results saved in 'molecular_analysis' directory\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
